### Дообучение на русскоязычном датасете (seara/ru_go_emotions)
Мы загружаем русскоязычную версию GoEmotions, выравниваем метки и выполняем дообучение модели для улучшения качества на русском.### Дообучение на русскоязычном датасете (seara/ru_go_emotions)
Ниже мы загружаем русскоязычную версию GoEmotions, выравниваем схему меток по именам и выполняем дополнительное дообучение той же модели для улучшения качества на русском.# Validate ONNX with ONNX Runtime
import onnxruntime as ort
import numpy as np

onnx_model_path = os.path.join(CFG.output_dir, 'onnx', 'model.onnx')
sess = ort.InferenceSession(onnx_model_path, providers=['CPUExecutionProvider'])

sample_text = 'Сегодня я чувствую лёгкую тревогу и сомнение, но также надежду.'
inputs = tokenizer(sample_text, return_tensors='np', max_length=CFG.max_length, truncation=True, padding='max_length')

# Prepare inputs for ORT
ort_inputs = {k: v for k, v in inputs.items()}
ort_outs = sess.run(None, ort_inputs)
onnx_logits = ort_outs[0]

# Compare with PyTorch
pt_logits = model(**tokenizer(sample_text, return_tensors='pt', max_length=CFG.max_length, truncation=True, padding='max_length')).logits.detach().cpu().numpy()
print('ONNX logits shape:', onnx_logits.shape, 'PT logits shape:', pt_logits.shape)
# EarlyStopping callback example (optional)
from transformers import EarlyStoppingCallback

early_stop = EarlyStoppingCallback(early_stopping_patience=2)

# To use early stopping, recreate the trainer with callbacks and train again (or pass in the first place)
# trainer = Trainer(
#     model=model,
#     args=args,
#     train_dataset=processed['train'],
#     eval_dataset=processed['validation'],
#     tokenizer=tokenizer,
#     data_collator=data_collator,
#     compute_metrics=compute_metrics,
#     callbacks=[early_stop]
# )
# trainer.train()
### Примечания по продакшену
- Для русскоязычных ответов улучшите качество через дообучение на русских датаcетах (например, `Kostya165/ru_emotion_dvach`) и/или self-training на ваших данных.
- Для мобильного инференса рассмотрите ONNX Runtime, CoreML (через onnx->coreml) или TensorRT-mobile (Android через NNAPI). Для KMP можно обернуть ONNX Runtime в нативный слой.
- Для стабильности: фиксируйте версии, логируйте артефакты, сохраняйте `label_names.json` и конфиг.
- Для дебайаса: добавьте контрольный срез по полу/возрасту/языку, кросс-лингвальную валидацию.
- Для приватности: анонимизируйте сырые тексты, храните только необходимые метаданные.
# Inference helper
import torch
import numpy as np
from typing import List, Optional
from transformers import AutoTokenizer, AutoModelForSequenceClassification

class EmotionClassifier:
    def __init__(self, model_path: str, label_names: List[str], thresholds_path: Optional[str] = None):
        self.tokenizer = AutoTokenizer.from_pretrained(model_path, use_fast=True)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.sigmoid = torch.nn.Sigmoid()
        self.label_names = label_names
        self.thresholds = None
        if thresholds_path and os.path.exists(thresholds_path):
            with open(thresholds_path) as f:
                self.thresholds = json.load(f)

    @torch.inference_mode()
    def predict(self, text: str, threshold: float = None, top_k: int = None, use_per_class_thresholds: bool = True):
        batch = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=CFG.max_length)
        logits = self.model(**batch).logits
        probs = self.sigmoid(logits)[0].cpu().numpy()

        if top_k is not None:
            idxs = probs.argsort()[::-1][:top_k]
            return [(self.label_names[i], float(probs[i])) for i in idxs]

        if threshold is None and self.thresholds is not None:
            if use_per_class_thresholds and 'per_class' in self.thresholds:
                thr = np.array(self.thresholds['per_class'])
                preds = probs >= thr
            else:
                thr = float(self.thresholds.get('global', 0.5))
                preds = probs >= thr
        else:
            thr = 0.5 if threshold is None else float(threshold)
            preds = probs >= thr

        idxs = np.where(preds)[0]
        return [(self.label_names[i], float(probs[i])) for i in idxs]

# Load labels & thresholds
with open(os.path.join(CFG.output_dir, 'label_names.json')) as f:
    label_names = json.load(f)

thr_path = os.path.join(CFG.output_dir, 'thresholds.json')
clf = EmotionClassifier(CFG.output_dir, label_names, thr_path)
print(clf.predict('I am so happy and grateful today!', top_k=5))
# Export to ONNX for mobile inference
from transformers.onnx import export
from transformers.onnx.features import FeaturesManager
from pathlib import Path

onnx_dir = Path(CFG.output_dir) / 'onnx'
onnx_dir.mkdir(parents=True, exist_ok=True)

feature = 'sequence-classification'
model_kind, model_onnx_config = FeaturesManager.check_supported_model_or_raise(model, feature=feature)
onnx_config = model_onnx_config(model.config)

dummy_input = tokenizer('Пример текста', return_tensors='pt', max_length=CFG.max_length)

export(
    preprocessor=tokenizer,
    model=model,
    config=onnx_config,
    opset=17,
    output=onnx_dir / 'model.onnx',
)

print('ONNX model saved to:', onnx_dir / 'model.onnx')
# Training
from transformers import TrainingArguments, Trainer, set_seed

set_seed(CFG.seed)

args = TrainingArguments(
    output_dir=CFG.output_dir,
    evaluation_strategy='epoch',
    save_strategy='epoch',
    logging_strategy='steps',
    logging_steps=100,
    learning_rate=CFG.learning_rate,
    per_device_train_batch_size=CFG.train_batch_size,
    per_device_eval_batch_size=CFG.eval_batch_size,
    num_train_epochs=CFG.num_epochs,
    weight_decay=CFG.weight_decay,
    warmup_ratio=CFG.warmup_ratio,
    fp16=CFG.fp16,
    load_best_model_at_end=True,
    metric_for_best_model='f1_macro',
    greater_is_better=True,
    report_to=['none'],
    save_total_limit=2,
)

trainer = Trainer(
    model=model,
    args=args,
    train_dataset=processed['train'],
    eval_dataset=processed['validation'],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer.train()

# Collect validation logits for threshold tuning
val_outputs = trainer.predict(processed['validation'])
val_probs = sigmoid(torch.tensor(val_outputs.predictions)).numpy()
val_labels = val_outputs.label_ids

thr_cfg = tune_thresholds(val_probs, val_labels)

with open(os.path.join(CFG.output_dir, 'thresholds.json'), 'w') as f:
    json.dump({
        'global': thr_cfg['global'],
        'per_class': thr_cfg['per_class'],
        'label_names': label_names
    }, f, ensure_ascii=False, indent=2)

print('Thresholds saved:', thr_cfg)

eval_metrics = trainer.evaluate(processed['test'])
print('Test metrics:', eval_metrics)

trainer.save_model(CFG.output_dir)
tokenizer.save_pretrained(CFG.output_dir)
# Metrics: F1 micro/macro, ROC-AUC macro
import evaluate
import numpy as np
from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve

sigmoid = torch.nn.Sigmoid()

GLOBAL_THRESHOLD = 0.5


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    probs = sigmoid(torch.tensor(logits)).numpy()
    preds = (probs >= GLOBAL_THRESHOLD).astype(int)

    metrics = {}
    try:
        metrics['roc_auc_macro'] = roc_auc_score(labels, probs, average='macro')
    except Exception:
        metrics['roc_auc_macro'] = float('nan')

    metrics['f1_micro'] = f1_score(labels, preds, average='micro', zero_division=0)
    metrics['f1_macro'] = f1_score(labels, preds, average='macro', zero_division=0)
    return metrics


def tune_thresholds(val_logits: np.ndarray, val_labels: np.ndarray):
    # Per-class threshold via Youden-like F1 sweep
    per_class = []
    for c in range(val_labels.shape[1]):
        y_true = val_labels[:, c]
        y_scores = val_logits[:, c]
        try:
            prec, rec, thresh = precision_recall_curve(y_true, y_scores)
            f1 = (2 * prec * rec) / (prec + rec + 1e-8)
            best_idx = int(np.argmax(f1))
            per_class.append(float(thresh[min(best_idx, len(thresh)-1)]) if len(thresh) > 0 else 0.5)
        except Exception:
            per_class.append(0.5)
    # Global threshold sweep
    candidate = np.linspace(0.2, 0.8, 25)
    best_thr, best_f1 = 0.5, -1
    for t in candidate:
        preds = (val_logits >= t).astype(int)
        f1m = f1_score(val_labels, preds, average='macro', zero_division=0)
        if f1m > best_f1:
            best_f1, best_thr = f1m, float(t)
    return {
        'global': best_thr,
        'per_class': per_class
    }
# Model setup (multi-label)
import torch
from transformers import AutoModelForSequenceClassification

model = AutoModelForSequenceClassification.from_pretrained(
    CFG.model_name,
    num_labels=num_labels,
    problem_type='multi_label_classification'
)

# Enable gradient checkpointing for memory efficiency on Colab GPUs
model.gradient_checkpointing_enable()

# For multi-label we will use BCEWithLogitsLoss via problem_type
# Data collator
from transformers import DataCollatorWithPadding

data_collator = DataCollatorWithPadding(tokenizer=tokenizer, pad_to_multiple_of=8 if CFG.fp16 else None)
# Tokenization & preprocessing
from transformers import AutoTokenizer
import numpy as np

tokenizer = AutoTokenizer.from_pretrained(CFG.model_name, use_fast=True)

def preprocess(examples):
    enc = tokenizer(examples[CFG.text_column], max_length=CFG.max_length, truncation=True, padding=False)
    # Convert multi-hot labels
    multi_hot = []
    for lbls in examples['labels']:
        arr = np.zeros(num_labels, dtype=np.float32)
        for idx in lbls:
            arr[idx] = 1.0
        multi_hot.append(arr)
    enc[CFG.label_column] = multi_hot
    return enc

remove_cols = dataset['train'].column_names  # drop all original columns; new ones will be added
processed = dataset.map(preprocess, batched=True, remove_columns=remove_cols)
processed = processed.with_format('torch')
processed
# Load dataset (GoEmotions multilabel variant)
from datasets import load_dataset

# 'raw' config is multilabel with 28 labels (27 emotions + neutral)
dataset = load_dataset(CFG.dataset_name, 'raw')
print(dataset)

# Inspect label names
label_names = dataset['train'].features['labels'].feature.names
num_labels = len(label_names)
print('Num labels:', num_labels)
print('Labels:', label_names)

with open(os.path.join(CFG.output_dir, 'label_names.json'), 'w') as f:
    json.dump(label_names, f, ensure_ascii=False, indent=2)
# Config
from dataclasses import dataclass

@dataclass
class Config:
    model_name: str = 'xlm-roberta-base'
    dataset_name: str = 'go_emotions'
    text_column: str = 'text'
    label_column: str = 'labels'
    max_length: int = 128
    train_batch_size: int = 32
    eval_batch_size: int = 32
    num_epochs: int = 3
    learning_rate: float = 2e-5
    weight_decay: float = 0.01
    warmup_ratio: float = 0.06
    output_dir: str = 'outputs/emotion_xlmr'
    fp16: bool = True
    seed: int = 42
    push_to_hub: bool = False

CFG = Config()
os.makedirs(CFG.output_dir, exist_ok=True)
print(CFG)
# Environment setup (Colab-safe)
import os, sys, subprocess, json, math

IN_COLAB = 'COLAB_GPU' in os.environ or 'COLAB_RELEASE_TAG' in os.environ or 'KAGGLE_KERNEL_RUN_TYPE' in os.environ

# Install deps if needed
reqs = [
    'torch',
    'transformers>=4.41.0',
    'datasets>=2.19.0',
    'evaluate>=0.4.2',
    'accelerate>=0.33.0',
    'scikit-learn>=1.3.0',
    'onnx>=1.15.0',
    'onnxruntime>=1.17.0',
]

def pip_install(packages):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + packages)

try:
    import transformers, datasets, evaluate, sklearn, onnxruntime
except Exception:
    pip_install(reqs)
    import transformers, datasets, evaluate, sklearn, onnxruntime

print('Transformers:', transformers.__version__)
print('Datasets:', datasets.__version__)
### Текстовая классификация эмоций (multilabel) для продакшена

Этот ноутбук обучает и экспортирует модель распознавания эмоций по тексту ответа пользователя. Он рассчитан на запуск в Google Colab и полностью автоматизирует:
- установку зависимостей;
- загрузку датасета и модели;
- обучение с логированием метрик;
- валидацию и расчёт F1 (micro/macro), ROC-AUC;
- сохранение артефактов (PyTorch + ONNX) и маппинг меток;
- пайплайн инференса с постпроцессингом (порог/`top_k`).

Выборы по умолчанию:
- **Датасет**: `go_emotions` (58k примеров, 28 меток включая `neutral`).
- **Модель**: `xlm-roberta-base` (многоязычная, хорошо переносится на русский).
- **Задача**: multi-label (одновременно несколько эмоций).

Примечание: для максимального качества на русском возможно дообучение на русскоязычных эмо-датаcетах. Базовая настройка ниже даёт сильную модель на английском с кросс-лингвальным переносом на русский благодаря XLM-R.