{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76Z0xTmVQt86",
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Финальный ноутбук: Распознавание эмоций по лицу для мобильного приложения\n",
        "\n",
        "Этот ноутбук тренирует компактную и точную модель распознавания эмоций, предназначенную для работы на устройстве (TensorFlow Lite / ONNX) и интеграции в Kotlin Multiplatform.\n",
        "\n",
        "- Датасеты: `train` (папки классов) и `test` (jpg-файлы), ссылки для автозагрузки ниже\n",
        "- Модель: EfficientNet-Lite0 (или MobileNetV3Small) с дообучением на ваших данных\n",
        "- Детекция лица: MTCNN или OpenCV DNN (выбор в настройках), кроп лица → классификация эмоций\n",
        "- Метрики: accuracy, F1-macro, confusion matrix, ROC-AUC per class\n",
        "- Визуализации: красивые лоссы/метрики, Grad-CAM, t-SNE feature embeddings\n",
        "- Экспорт: TFLite (float16 или int8) и ONNX (опционально) + примеры вызова из Kotlin\n",
        "\n",
        "В ноутбуке предусмотрены прогресс-бары и информативные логи этапов, чтобы было понятно, что происходит на каждом шаге.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlBJ-r2jQt87"
      },
      "outputs": [],
      "source": [
        "# --- Установка и импорт зависимостей (Colab) ---\n",
        "!pip -q install -U 'tensorflow==2.19.0' onnx onnxruntime-gpu onnxconverter-common tf2onnx mtcnn 'opencv-python-headless==4.10.0.84' 'albumentations==1.4.7' seaborn 'rich<14' kaggle gdown --no-warn-script-location\n",
        "\n",
        "import os, sys, time, json, random, shutil, zipfile, glob, math, pathlib\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from mtcnn import MTCNN\n",
        "import cv2\n",
        "\n",
        "import albumentations as A\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.progress import track\n",
        "\n",
        "console = Console()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qmrSjCh-Qt87"
      },
      "outputs": [],
      "source": [
        "# --- Конфигурация проекта ---\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# пути к датасетам в Colab (будут скачаны)\n",
        "BASE_DIR = Path.cwd()\n",
        "DATA_DIR = BASE_DIR / 'data'\n",
        "TRAIN_DIR = DATA_DIR / 'train'\n",
        "TEST_DIR  = DATA_DIR / 'test'\n",
        "DATA_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# классы эмоций (по структуре вашего train)\n",
        "CLASS_NAMES = ['anger','contempt','disgust','fear','happy','neutral','sad','surprise','uncertain']\n",
        "N_CLASSES = len(CLASS_NAMES)\n",
        "\n",
        "# изображение\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# геометрия детектора и выбор\n",
        "FACE_DETECTOR = 'mtcnn'  # 'mtcnn' | 'cv-dnn'\n",
        "\n",
        "# обучение\n",
        "EPOCHS = 20\n",
        "BASE_LR = 3e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "# экспорт\n",
        "DO_TFLITE_FP16 = True\n",
        "DO_TFLITE_INT8 = False\n",
        "DO_ONNX = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "ntGOl_31Qt87",
        "outputId": "c9c2ad20-428e-496d-d8c3-d544e60ba771"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Файл train.zip не похож на ZIP, пробую gdown...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[33mФайл train.zip не похож на ZIP, пробую gdown\u001b[0m\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16\n",
            "From (redirected): https://drive.google.com/uc?id=1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16&confirm=t&uuid=22126ad0-c5f6-4c84-844c-84c469ff458a\n",
            "To: /content/data/train.zip\n",
            "100%|██████████| 2.28G/2.28G [00:11<00:00, 207MB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Распаковываю train...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36mРаспаковываю train\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Скачиваю test.zip...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[36mСкачиваю test.zip\u001b[0m\u001b[36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Готово: /content/data/test.zip</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32mГотово: \u001b[0m\u001b[32m/content/data/\u001b[0m\u001b[32mtest.zip\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">Файл test.zip не похож на ZIP, пробую gdown...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[33mФайл test.zip не похож на ZIP, пробую gdown\u001b[0m\u001b[33m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K\n",
            "From (redirected): https://drive.google.com/uc?id=12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K&confirm=t&uuid=12edb4b8-f326-42f3-ba55-e78eabc422d7\n",
            "To: /content/data/test.zip\n",
            "100%|██████████| 222M/222M [00:01<00:00, 203MB/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Распаковываю test...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36mРаспаковываю test\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Готово. Структура:</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;32mГотово. Структура:\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> - <span style=\"color: #800080; text-decoration-color: #800080\">/content/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">test.zip</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              " - \u001b[35m/content/data/\u001b[0m\u001b[95mtest.zip\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> - <span style=\"color: #800080; text-decoration-color: #800080\">/content/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">test_kaggle</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              " - \u001b[35m/content/data/\u001b[0m\u001b[95mtest_kaggle\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> - <span style=\"color: #800080; text-decoration-color: #800080\">/content/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">train</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              " - \u001b[35m/content/data/\u001b[0m\u001b[95mtrain\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> - <span style=\"color: #800080; text-decoration-color: #800080\">/content/data/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">train.zip</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              " - \u001b[35m/content/data/\u001b[0m\u001b[95mtrain.zip\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Загрузка датасетов из ссылок ---\n",
        "\n",
        "import requests, zipfile\n",
        "import gdown\n",
        "\n",
        "TRAIN_ZIP_URL = 'https://drive.usercontent.google.com/download?id=1TG9P5B2k3eTbC4XDxDmEc07dyAORPC16&export=download&authuser=0'\n",
        "TEST_ZIP_URL  = 'https://drive.usercontent.google.com/download?id=12QrDrLT1F-X7UycvOoApXFqxTw3Zx93K&export=download&authuser=0'\n",
        "\n",
        "train_zip = DATA_DIR / 'train.zip'\n",
        "test_zip  = DATA_DIR / 'test.zip'\n",
        "\n",
        "\n",
        "def _extract_id(url: str):\n",
        "    try:\n",
        "        return url.split('id=')[1].split('&')[0]\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def _ensure_zip(url: str, dest: Path):\n",
        "    # Сначала обычная загрузка\n",
        "    if not dest.exists():\n",
        "        console.print(f'[cyan]Скачиваю {dest.name}...[/cyan]')\n",
        "        with requests.get(url, stream=True) as r:\n",
        "            r.raise_for_status()\n",
        "            with open(dest, 'wb') as f:\n",
        "                for chunk in r.iter_content(chunk_size=1<<20):\n",
        "                    if chunk:\n",
        "                        f.write(chunk)\n",
        "        console.print(f'[green]Готово: {dest}[/green]')\n",
        "    # Проверим, zip ли это\n",
        "    if not zipfile.is_zipfile(dest):\n",
        "        console.print(f'[yellow]Файл {dest.name} не похож на ZIP, пробую gdown...[/yellow]')\n",
        "        file_id = _extract_id(url)\n",
        "        if file_id:\n",
        "            gdown.download(id=file_id, output=str(dest), quiet=False)\n",
        "        else:\n",
        "            gdown.download(url=url, output=str(dest), quiet=False, fuzzy=True)\n",
        "    if not zipfile.is_zipfile(dest):\n",
        "        raise RuntimeError(f'Не удалось получить валидный ZIP: {dest}')\n",
        "\n",
        "\n",
        "def _safe_unzip(zip_path: Path, target_dir: Path, title: str):\n",
        "    console.print(f'[bold cyan]Распаковываю {title}...[/bold cyan]')\n",
        "    try:\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "            zf.extractall(target_dir)\n",
        "    except zipfile.BadZipFile:\n",
        "        console.print(f'[yellow]Поврежденный ZIP, повторная загрузка через gdown...[/yellow]')\n",
        "        file_id = _extract_id(TRAIN_ZIP_URL if 'train' in zip_path.name else TEST_ZIP_URL)\n",
        "        gdown.download(id=file_id, output=str(zip_path), quiet=False)\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
        "            zf.extractall(target_dir)\n",
        "\n",
        "\n",
        "if not TRAIN_DIR.exists():\n",
        "    _ensure_zip(TRAIN_ZIP_URL, train_zip)\n",
        "    _safe_unzip(train_zip, DATA_DIR, 'train')\n",
        "\n",
        "if not TEST_DIR.exists():\n",
        "    _ensure_zip(TEST_ZIP_URL, test_zip)\n",
        "    _safe_unzip(test_zip, DATA_DIR, 'test')\n",
        "\n",
        "console.print('[bold green]Готово. Структура:[/bold green]')\n",
        "for p in sorted(DATA_DIR.glob('*')):\n",
        "    console.print(' -', p)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "Q2QhMNZ6Qt87",
        "outputId": "d9649b1c-9786-47ea-d181-b4facf2c928d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Скачиваю deploy.prototxt...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[36mСкачиваю deploy.prototxt\u001b[0m\u001b[36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Готово: /content/data/cv_dnn/deploy.prototxt</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32mГотово: \u001b[0m\u001b[32m/content/data/cv_dnn/\u001b[0m\u001b[32mdeploy.prototxt\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080\">Скачиваю res10_30</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x300</span><span style=\"color: #008080; text-decoration-color: #008080\">_ssd_iter_140000.caffemodel...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[36mСкачиваю res10_30\u001b[0m\u001b[1;36m0x300\u001b[0m\u001b[36m_ssd_iter_140000.caffemodel\u001b[0m\u001b[36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Готово: /content/data/cv_dnn/res10_300x300_ssd_iter_140000.caffemodel</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[32mГотово: \u001b[0m\u001b[32m/content/data/cv_dnn/\u001b[0m\u001b[32mres10_300x300_ssd_iter_140000.caffemodel\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# --- Детекция лица: MTCNN и OpenCV DNN ---\n",
        "\n",
        "import requests\n",
        "\n",
        "def get_mtcnn_detector():\n",
        "    return MTCNN()\n",
        "\n",
        "# Pretrained OpenCV DNN (res10_300x300_ssd)\n",
        "PROTO_URL = 'https://raw.githubusercontent.com/opencv/opencv/master/samples/dnn/face_detector/deploy.prototxt'\n",
        "CAFFE_MODEL_URL = 'https://raw.githubusercontent.com/opencv/opencv_3rdparty/dnn_samples_face_detector_20170830/res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "DNN_DIR = DATA_DIR / 'cv_dnn'\n",
        "DNN_DIR.mkdir(exist_ok=True)\n",
        "PROTO_PATH = DNN_DIR / 'deploy.prototxt'\n",
        "MODEL_PATH = DNN_DIR / 'res10_300x300_ssd_iter_140000.caffemodel'\n",
        "\n",
        "def _download(url: str, dest: Path):\n",
        "    if dest.exists():\n",
        "        return\n",
        "    console.print(f\"[cyan]Скачиваю {dest.name}...[/cyan]\")\n",
        "    with requests.get(url, stream=True) as r:\n",
        "        r.raise_for_status()\n",
        "        with open(dest, 'wb') as f:\n",
        "            for chunk in r.iter_content(chunk_size=8192):\n",
        "                if chunk:\n",
        "                    f.write(chunk)\n",
        "    console.print(f\"[green]Готово: {dest}[/green]\")\n",
        "\n",
        "_download(PROTO_URL, PROTO_PATH)\n",
        "_download(CAFFE_MODEL_URL, MODEL_PATH)\n",
        "\n",
        "def get_cv_dnn_detector():\n",
        "    return cv2.dnn.readNetFromCaffe(str(PROTO_PATH), str(MODEL_PATH))\n",
        "\n",
        "\n",
        "def detect_and_crop_face(image_bgr: np.ndarray, detector_type: str='mtcnn'):\n",
        "    h, w = image_bgr.shape[:2]\n",
        "    if detector_type == 'mtcnn':\n",
        "        detector = get_mtcnn_detector()\n",
        "        faces = detector.detect_faces(cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB))\n",
        "        if not faces:\n",
        "            return None\n",
        "        x, y, width, height = faces[0]['box']\n",
        "        x, y = max(0, x), max(0, y)\n",
        "        return image_bgr[y:y+height, x:x+width]\n",
        "    else:\n",
        "        net = get_cv_dnn_detector()\n",
        "        blob = cv2.dnn.blobFromImage(image_bgr, 1.0, (300, 300), (104.0, 177.0, 123.0), swapRB=True)\n",
        "        net.setInput(blob)\n",
        "        detections = net.forward()\n",
        "        conf_threshold = 0.5\n",
        "        best = None\n",
        "        for i in range(detections.shape[2]):\n",
        "            confidence = detections[0, 0, i, 2]\n",
        "            if confidence > conf_threshold:\n",
        "                box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
        "                (x1, y1, x2, y2) = box.astype('int')\n",
        "                best = (max(0, x1), max(0, y1), min(w, x2)-x1, min(h, y2)-y1)\n",
        "                break\n",
        "        if best is None:\n",
        "            return None\n",
        "        x, y, width, height = best\n",
        "        return image_bgr[y:y+height, x:x+width]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 274
        },
        "id": "PeJtE8KiQt88",
        "outputId": "1a9a5878-5d86-4405-dd02-f94e7138523e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Train</span>:\n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42539</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "  <span style=\"font-weight: bold\">Val</span>:\n",
              "<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7508</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mTrain\u001b[0m:\n",
              "\u001b[1m(\u001b[0m\u001b[1;36m42539\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n",
              "  \u001b[1mVal\u001b[0m:\n",
              "\u001b[1m(\u001b[0m\u001b[1;36m7508\u001b[0m, \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"tr_df\",\n  \"rows\": 42539,\n  \"fields\": [\n    {\n      \"column\": \"path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 42539,\n        \"samples\": [\n          \"/content/data/train/disgust/213.jpg\",\n          \"/content/data/train/surprise/3876.jpg\",\n          \"/content/data/train/neutral/2214.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          2,\n          5,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "tr_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-8c4e3e76-98ff-4479-b4b8-837efca9daa5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/data/train/fear/1485.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/data/train/neutral/2735.jpg</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/data/train/uncertain/178.jpg</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/data/train/fear/3581.jpg</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/data/train/sad/1422.jpg</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c4e3e76-98ff-4479-b4b8-837efca9daa5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8c4e3e76-98ff-4479-b4b8-837efca9daa5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8c4e3e76-98ff-4479-b4b8-837efca9daa5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5919ed95-aeee-47f0-93f5-bef935cb1e0c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5919ed95-aeee-47f0-93f5-bef935cb1e0c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5919ed95-aeee-47f0-93f5-bef935cb1e0c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                    path  label\n",
              "0      /content/data/train/fear/1485.jpg      3\n",
              "1   /content/data/train/neutral/2735.jpg      5\n",
              "2  /content/data/train/uncertain/178.jpg      8\n",
              "3      /content/data/train/fear/3581.jpg      3\n",
              "4       /content/data/train/sad/1422.jpg      6"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# --- Подготовка списков файлов и train/val split ---\n",
        "\n",
        "def collect_dataset(train_dir: Path):\n",
        "    image_paths, labels = [], []\n",
        "    for class_idx, class_name in enumerate(CLASS_NAMES):\n",
        "        class_dir = train_dir / class_name\n",
        "        for p in class_dir.glob('*.jpg'):\n",
        "            image_paths.append(str(p))\n",
        "            labels.append(class_idx)\n",
        "    return pd.DataFrame({'path': image_paths, 'label': labels})\n",
        "\n",
        "train_df = collect_dataset(TRAIN_DIR)\n",
        "train_df = train_df.sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
        "\n",
        "tr_df, val_df = train_test_split(train_df, test_size=0.15, stratify=train_df['label'], random_state=SEED)\n",
        "tr_df = tr_df.reset_index(drop=True)\n",
        "val_df = val_df.reset_index(drop=True)\n",
        "\n",
        "console.print('[bold]Train[/bold]:', tr_df.shape, '  [bold]Val[/bold]:', val_df.shape)\n",
        "tr_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "HUqFHxAOQt88",
        "outputId": "7d9c8fe6-99d4-4c0b-fc09-813c7e342e10"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-3730348829.py:11: UserWarning: Argument(s) 'cval, mode' are not valid for transform Affine\n",
            "  A.Affine(scale=(0.9, 1.1), translate_percent=(-0.02, 0.02), rotate=(-10, 10),\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "module 'albumentations' has no attribute 'Cutout'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3730348829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     A.Affine(scale=(0.9, 1.1), translate_percent=(-0.02, 0.02), rotate=(-10, 10),\n\u001b[1;32m     12\u001b[0m              cval=0, mode=cv2.BORDER_REFLECT_101, p=0.5),\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCutout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_holes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_h_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_w_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m ])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'albumentations' has no attribute 'Cutout'"
          ]
        }
      ],
      "source": [
        "# --- Аугментации и препроцессинг ---\n",
        "\n",
        "train_transform = A.Compose([\n",
        "    A.LongestMaxSize(max_size=IMG_SIZE, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(IMG_SIZE, IMG_SIZE, border_mode=cv2.BORDER_REFLECT_101),\n",
        "    A.OneOf([\n",
        "        A.RandomBrightnessContrast(0.15, 0.15, p=1.0),\n",
        "        A.CLAHE(clip_limit=2.0, p=1.0),\n",
        "    ], p=0.5),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Affine(\n",
        "        scale=(0.9, 1.1), translate_percent=(-0.02, 0.02), rotate=(-10, 10),\n",
        "        shear=(-5, 5),\n",
        "        mode=cv2.BORDER_REFLECT_101, cval=0, p=0.5\n",
        "    ),\n",
        "    A.CoarseDropout(\n",
        "        min_holes=4, max_holes=4,\n",
        "        min_height=IMG_SIZE // 32, min_width=IMG_SIZE // 32,\n",
        "        max_height=IMG_SIZE // 16, max_width=IMG_SIZE // 16,\n",
        "        fill_value=0, p=0.3\n",
        "    ),\n",
        "])\n",
        "\n",
        "val_transform = A.Compose([\n",
        "    A.LongestMaxSize(max_size=IMG_SIZE, interpolation=cv2.INTER_CUBIC),\n",
        "    A.PadIfNeeded(IMG_SIZE, IMG_SIZE, border_mode=cv2.BORDER_REFLECT_101),\n",
        "])\n",
        "\n",
        "\n",
        "def read_image_and_face_crop(path: str):\n",
        "    bgr = cv2.imread(path)\n",
        "    if bgr is None:\n",
        "        raise ValueError(f'Не удалось прочитать: {path}')\n",
        "    face = detect_and_crop_face(bgr, FACE_DETECTOR)\n",
        "    if face is None:\n",
        "        face = bgr\n",
        "    return face\n",
        "\n",
        "\n",
        "def preprocess_image(path: str, is_train: bool):\n",
        "    face = read_image_and_face_crop(path)\n",
        "    if is_train:\n",
        "        aug = train_transform(image=face)\n",
        "    else:\n",
        "        aug = val_transform(image=face)\n",
        "    image = aug['image']\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "    return image\n",
        "\n",
        "\n",
        "def build_tf_dataset(df: pd.DataFrame, is_train: bool):\n",
        "    paths = df['path'].values\n",
        "    labels = df['label'].values\n",
        "\n",
        "    def _py_map(path, label):\n",
        "        path = path.decode()\n",
        "        image = preprocess_image(path, is_train)\n",
        "        return image, np.int32(label)\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
        "    if is_train:\n",
        "        ds = ds.shuffle(4096, seed=SEED, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(lambda p, y: tf.numpy_function(_py_map, [p, y], [tf.float32, tf.int32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.map(lambda x, y: (tf.ensure_shape(x, [IMG_SIZE, IMG_SIZE, 3]), tf.ensure_shape(tf.cast(y, tf.int32), [])))\n",
        "    ds = ds.batch(BATCH_SIZE, drop_remainder=True).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "train_ds = build_tf_dataset(tr_df, True)\n",
        "val_ds   = build_tf_dataset(val_df, False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "8_Ns5RLZQt88",
        "outputId": "1697cd28-4fee-4505-e60d-78605514bcbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Этап </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">: дообучение головы...</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36mЭтап \u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;36m: дообучение головы\u001b[0m\u001b[1;36m...\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "Cannot take the length of shape with unknown rank.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2860780878.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mconsole\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[bold cyan]Этап 1: дообучение головы...[/bold cyan]'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mhist1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Fine-tune: разморозим часть слоев\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/optree/ops.py\u001b[0m in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0mleaves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreespec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_is_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0mflat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mleaves\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_up_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrests\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 766\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtreespec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mflat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot take the length of shape with unknown rank."
          ]
        }
      ],
      "source": [
        "# --- Модель: EfficientNet-Lite0 с дообучением ---\n",
        "\n",
        "# Используем легкую архитектуру для on-device\n",
        "base_model = tf.keras.applications.EfficientNetB0(\n",
        "    include_top=False, weights='imagenet', input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
        ")\n",
        "\n",
        "# Заморозим основу на раннем этапе, затем разморозим для fine-tune\n",
        "base_model.trainable = False\n",
        "\n",
        "inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D(name='gap')(x)\n",
        "x = layers.Dropout(0.2)(x)\n",
        "outputs = layers.Dense(N_CLASSES, activation='softmax', name='output')(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# Под drop_remainder=True используем целочисленные шаги\n",
        "steps_per_epoch = len(tr_df) // BATCH_SIZE\n",
        "validation_steps = len(val_df) // BATCH_SIZE\n",
        "\n",
        "optimizer = keras.optimizers.AdamW(learning_rate=BASE_LR, weight_decay=WEIGHT_DECAY)\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "ckpt_dir = BASE_DIR / 'checkpoints'\n",
        "ckpt_dir.mkdir(exist_ok=True)\n",
        "ckpt_path = str(ckpt_dir / 'model.{epoch:02d}-{val_accuracy:.4f}.h5')\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(filepath=ckpt_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "console.print('[bold cyan]Этап 1: дообучение головы...[/bold cyan]')\n",
        "hist1 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS//2,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        ")\n",
        "\n",
        "# Fine-tune: разморозим часть слоев\n",
        "console.print('[bold cyan]Этап 2: fine-tune бэкбона...[/bold cyan]')\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:150]:\n",
        "    layer.trainable = False\n",
        "optimizer_finetune = keras.optimizers.AdamW(learning_rate=BASE_LR/10, weight_decay=WEIGHT_DECAY)\n",
        "model.compile(optimizer=optimizer_finetune, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "hist2 = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS//2,\n",
        "    callbacks=callbacks,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        ")\n",
        "\n",
        "history = {}\n",
        "for k in hist1.history:\n",
        "    history[k] = hist1.history[k] + hist2.history.get(k, [])\n",
        "\n",
        "console.print('[bold green]Обучение завершено[/bold green]')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9YWnwhQQt88"
      },
      "outputs": [],
      "source": [
        "# --- Визуализация истории обучения ---\n",
        "\n",
        "def plot_history(hist):\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(14,5))\n",
        "    axs[0].plot(hist['loss'], label='train_loss')\n",
        "    axs[0].plot(hist['val_loss'], label='val_loss')\n",
        "    axs[0].legend(); axs[0].set_title('Loss'); axs[0].grid(True)\n",
        "    axs[1].plot(hist['accuracy'], label='train_acc')\n",
        "    axs[1].plot(hist['val_accuracy'], label='val_acc')\n",
        "    axs[1].legend(); axs[1].set_title('Accuracy'); axs[1].grid(True)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RK9o9n1Qt88"
      },
      "outputs": [],
      "source": [
        "# --- Оценка на валидации: отчеты и матрица ошибок ---\n",
        "\n",
        "val_images, val_labels = [], []\n",
        "for path, label in val_df[['path','label']].values:\n",
        "    val_images.append(preprocess_image(path, is_train=False))\n",
        "    val_labels.append(label)\n",
        "val_images = np.stack(val_images)\n",
        "val_labels = np.array(val_labels)\n",
        "\n",
        "val_probs = model.predict(val_images, batch_size=BATCH_SIZE)\n",
        "val_pred = val_probs.argmax(axis=1)\n",
        "\n",
        "# Классификационный отчет\n",
        "report = classification_report(val_labels, val_pred, target_names=CLASS_NAMES, digits=4)\n",
        "print(report)\n",
        "\n",
        "# Матрица ошибок\n",
        "cm = confusion_matrix(val_labels, val_pred)\n",
        "plt.figure(figsize=(9,7))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=CLASS_NAMES, yticklabels=CLASS_NAMES)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True'); plt.xlabel('Predicted');\n",
        "plt.show()\n",
        "\n",
        "# ROC-AUC по классам (one-vs-rest)\n",
        "y_true_bin = label_binarize(val_labels, classes=list(range(N_CLASSES)))\n",
        "try:\n",
        "    roc_auc = roc_auc_score(y_true_bin, val_probs, average=None)\n",
        "    for i, c in enumerate(CLASS_NAMES):\n",
        "        print(f'ROC-AUC[{c}] = {roc_auc[i]:.4f}')\n",
        "    print(f'Macro ROC-AUC = {roc_auc.mean():.4f}')\n",
        "except ValueError:\n",
        "    print('ROC-AUC не посчитан (возможно один класс не предсказан)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ4jsnZ8Qt89"
      },
      "outputs": [],
      "source": [
        "# --- Grad-CAM визуализация важных областей ---\n",
        "from tensorflow.keras.preprocessing import image as kimage\n",
        "\n",
        "last_conv_layer_name = None\n",
        "for layer in reversed(model.layers):\n",
        "    if isinstance(layer, layers.Conv2D):\n",
        "        last_conv_layer_name = layer.name\n",
        "        break\n",
        "\n",
        "if last_conv_layer_name is None:\n",
        "    # Возьмем последнюю conv из base_model\n",
        "    for layer in reversed(base_model.layers):\n",
        "        if isinstance(layer, layers.Conv2D):\n",
        "            last_conv_layer_name = layer.name\n",
        "            break\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_outputs, predictions = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(predictions[0])\n",
        "        class_channel = predictions[:, pred_index]\n",
        "    grads = tape.gradient(class_channel, conv_outputs)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "    conv_outputs = conv_outputs[0]\n",
        "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-8)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "# Визуализируем несколько карт\n",
        "num_show = min(6, len(val_images))\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(num_show):\n",
        "    img = val_images[i]\n",
        "    inp = np.expand_dims(img, 0)\n",
        "    heatmap = make_gradcam_heatmap(inp, model, last_conv_layer_name)\n",
        "    heatmap = cv2.resize(heatmap, (IMG_SIZE, IMG_SIZE))\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "    overlay = cv2.addWeighted((img*255).astype(np.uint8), 0.6, heatmap, 0.4, 0)\n",
        "    plt.subplot(2, (num_show+1)//2, i+1)\n",
        "    plt.axis('off')\n",
        "    plt.title(CLASS_NAMES[val_labels[i]])\n",
        "    plt.imshow(overlay)\n",
        "plt.suptitle('Grad-CAM важные области')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8K1DjXacQt89"
      },
      "outputs": [],
      "source": [
        "# --- Экспорт в TFLite и ONNX ---\n",
        "export_dir = BASE_DIR / 'export'\n",
        "export_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Сохранение Keras\n",
        "keras_path = export_dir / 'fer_model.h5'\n",
        "model.save(keras_path)\n",
        "console.print('[green]Сохранено:[/green]', keras_path)\n",
        "\n",
        "# TFLite float16\n",
        "if DO_TFLITE_FP16:\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "    tflite_model = converter.convert()\n",
        "    tflite_fp16_path = export_dir / 'fer_model_fp16.tflite'\n",
        "    with open(tflite_fp16_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    console.print('[green]TFLite FP16:[/green]', tflite_fp16_path)\n",
        "\n",
        "# TFLite int8 (post-training quantization) с калибровкой на подвыборке\n",
        "if DO_TFLITE_INT8:\n",
        "    def representative_dataset():\n",
        "        for i in range(100):\n",
        "            idx = np.random.randint(0, len(tr_df))\n",
        "            img = preprocess_image(tr_df.iloc[idx]['path'], is_train=False)\n",
        "            yield [np.expand_dims(img.astype(np.float32), 0)]\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_dataset\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.uint8\n",
        "    converter.inference_output_type = tf.uint8\n",
        "    tflite_int8 = converter.convert()\n",
        "    tflite_int8_path = export_dir / 'fer_model_int8.tflite'\n",
        "    with open(tflite_int8_path, 'wb') as f:\n",
        "        f.write(tflite_int8)\n",
        "    console.print('[green]TFLite INT8:[/green]', tflite_int8_path)\n",
        "\n",
        "# ONNX\n",
        "if DO_ONNX:\n",
        "    import tf2onnx\n",
        "    spec = (tf.TensorSpec((None, IMG_SIZE, IMG_SIZE, 3), tf.float32, name='input'),)\n",
        "    onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)\n",
        "    onnx_path = export_dir / 'fer_model.onnx'\n",
        "    with open(onnx_path, 'wb') as f:\n",
        "        f.write(onnx_model.SerializeToString())\n",
        "    console.print('[green]ONNX:[/green]', onnx_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJ0uGHvcQt89"
      },
      "outputs": [],
      "source": [
        "## Интеграция в Kotlin Multiplatform (Android/iOS)\n",
        "\n",
        "- Экспортируйте TFLite-модель `fer_model_fp16.tflite` (или `fer_model_int8.tflite` для ускорения)\n",
        "- На Android используйте `org.tensorflow:tensorflow-lite` и `tensorflow-lite-select-tf-ops` при необходимости\n",
        "- На iOS можно использовать TensorFlowLiteSwift или переложить ONNX в CoreML через coremltools\n",
        "- Предобработка на устройстве: MTCNN сравнительно тяжелый; на проде используйте MediaPipe Face Detection (BlazeFace) для реального времени, затем кроп лица → ресайз до 224x224 → нормализация 0..1 → TFLite-инференс\n",
        "\n",
        "Пример псевдокода (Android, TFLite):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ExE6p-JQt89"
      },
      "outputs": [],
      "source": [
        "// val tfliteModel = FileUtil.loadMappedFile(context, \"fer_model_fp16.tflite\")\n",
        "// val interpreter = Interpreter(tfliteModel, Interpreter.Options().apply {\n",
        "//     setNumThreads(4)\n",
        "// })\n",
        "// val input = ByteBuffer.allocateDirect(1 * 224 * 224 * 3 * 4).order(ByteOrder.nativeOrder())\n",
        "// val output = ByteBuffer.allocateDirect(1 * 9 * 4).order(ByteOrder.nativeOrder())\n",
        "// preprocess(faceBitmap, input) // resize 224x224, float32 0..1\n",
        "// interpreter.run(input, output)\n",
        "// val probs = FloatArray(9)\n",
        "// output.asFloatBuffer().get(probs)\n",
        "// val emotionIdx = probs.indices.maxBy { probs[it] }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBg-Vl-pQt89"
      },
      "outputs": [],
      "source": [
        "# --- Экспорт метрик и артефактов ---\n",
        "metrics = {\n",
        "    'classes': CLASS_NAMES,\n",
        "    'val_accuracy': float(history['val_accuracy'][-1]) if len(history['val_accuracy'])>0 else None,\n",
        "}\n",
        "metrics_path = export_dir / 'metrics.json'\n",
        "with open(metrics_path, 'w', encoding='utf-8') as f:\n",
        "    json.dump(metrics, f, ensure_ascii=False, indent=2)\n",
        "console.print('[green]Сохранены метрики:[/green]', metrics_path)\n",
        "\n",
        "# t-SNE визуализация эмбеддингов\n",
        "feat_model = keras.Model(model.input, model.get_layer('gap').output)\n",
        "embeds = feat_model.predict(val_images, batch_size=BATCH_SIZE)\n",
        "tsne = TSNE(n_components=2, random_state=SEED, init='pca', learning_rate='auto')\n",
        "emb2d = tsne.fit_transform(embeds)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "for i, c in enumerate(CLASS_NAMES):\n",
        "    idx = np.where(val_labels==i)[0]\n",
        "    plt.scatter(emb2d[idx,0], emb2d[idx,1], s=10, label=c)\n",
        "plt.legend(ncol=3)\n",
        "plt.title('t-SNE feature embeddings (val)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
