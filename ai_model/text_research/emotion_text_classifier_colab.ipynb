# Inference helper
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch, json, numpy as np

class EmotionClassifier:
    def __init__(self, model_dir):
        self.tokenizer = AutoTokenizer.from_pretrained(model_dir, use_fast=True)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        self.sigmoid = torch.nn.Sigmoid()
        with open(os.path.join(model_dir, 'label_names.json')) as f:
            self.labels = json.load(f)
        thr_path = os.path.join(model_dir, 'thresholds.json')
        self.thresholds = json.load(open(thr_path)) if os.path.exists(thr_path) else None

    @torch.inference_mode()
    def predict(self, text, top_k=None, threshold=None):
        batch = self.tokenizer(text, return_tensors='pt', truncation=True, max_length=CFG.max_length)
        probs = self.sigmoid(self.model(**batch).logits)[0].cpu().numpy()
        if top_k is not None:
            idx = probs.argsort()[::-1][:top_k]
            return [(self.labels[i], float(probs[i])) for i in idx]
        thr = threshold
        if thr is None and self.thresholds is not None:
            thr = float(self.thresholds.get('global', 0.5))
        if thr is None:
            thr = 0.5
        idx = np.where(probs >= thr)[0]
        return [(self.labels[i], float(probs[i])) for i in idx]

clf = EmotionClassifier(CFG.out_dir)
print(clf.predict('Сегодня я чувствую лёгкую тревогу и сомнение, но также надежду.', top_k=5))
# Save model/tokenizer and export ONNX
from transformers.onnx import export
from transformers.onnx.features import FeaturesManager
from pathlib import Path

save_dir = CFG.out_dir
trainer_ru.save_model(save_dir)
tokenizer.save_pretrained(save_dir)

onnx_dir = Path(save_dir) / 'onnx'
onx_feature = 'sequence-classification'
onnx_dir.mkdir(parents=True, exist_ok=True)

_, onnx_cfg_cls = FeaturesManager.check_supported_model_or_raise(model, feature=onx_feature)
onnx_cfg = onnx_cfg_cls(model.config)

export(preprocessor=tokenizer, model=model, config=onnx_cfg, opset=17, output=onnx_dir / 'model.onnx')
print('ONNX saved to', onnx_dir / 'model.onnx')
# Evaluate on RU test
metrics_ru = trainer_ru.evaluate(ru_proc['test'])
print('RU test metrics:', metrics_ru)
# Re-tune thresholds on combined EN+RU validation
val_en = trainer.predict(en_proc['validation'])
val_ru = trainer_ru.predict(ru_proc['validation'])
probs_en = sigmoid(torch.tensor(val_en.predictions)).numpy()
probs_ru = sigmoid(torch.tensor(val_ru.predictions)).numpy()
labels_en = val_en.label_ids
labels_ru = val_ru.label_ids

probs_all = np.concatenate([probs_en, probs_ru], axis=0)
labels_all = np.concatenate([labels_en, labels_ru], axis=0)

thr_all = tune_thresholds(probs_all, labels_all)
with open(os.path.join(CFG.out_dir, 'thresholds.json'), 'w') as f:
    json.dump({'global': thr_all['global'], 'per_class': thr_all['per_class'], 'label_names': label_names}, f, ensure_ascii=False, indent=2)
print('Combined thresholds saved:', thr_all)
# Continue fine-tuning on RU
args_ru = TrainingArguments(
    output_dir=os.path.join(CFG.out_dir, 'ru_ft'),
    evaluation_strategy='epoch',
    save_strategy='epoch',
    learning_rate=CFG.lr,
    per_device_train_batch_size=CFG.train_bs,
    per_device_eval_batch_size=CFG.eval_bs,
    num_train_epochs=CFG.epochs_ru,
    weight_decay=CFG.wd,
    warmup_ratio=CFG.warmup_ratio,
    fp16=CFG.fp16,
    load_best_model_at_end=True,
    metric_for_best_model='f1_macro',
    greater_is_better=True,
    report_to=['none'],
    save_total_limit=2,
)

trainer_ru = Trainer(
    model=model,
    args=args_ru,
    train_dataset=ru_proc['train'],
    eval_dataset=ru_proc['validation'],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)
trainer_ru.train()
# Load RU GoEmotions translation
ru_ds = load_dataset('seara/ru_go_emotions')
# Expect same label schema names; verify and map by name
ru_label_names = ru_ds['train'].features['labels'].feature.names
assert list(ru_label_names) == list(label_names), 'RU label schema mismatch with EN GoEmotions'

ru_proc = preprocess(ru_ds).with_format('torch')
print('RU splits:', ru_ds)
# Tune thresholds on EN validation
val_outputs = trainer.predict(en_proc['validation'])
val_probs = sigmoid(torch.tensor(val_outputs.predictions)).numpy()
val_labels = val_outputs.label_ids

from sklearn.metrics import f1_score, precision_recall_curve

def tune_thresholds(val_logits: np.ndarray, val_labels: np.ndarray):
    per_class = []
    for c in range(val_labels.shape[1]):
        y_true = val_labels[:, c]
        y_scores = val_logits[:, c]
        try:
            prec, rec, thr = precision_recall_curve(y_true, y_scores)
            f1 = (2*prec*rec)/(prec+rec+1e-8)
            bi = int(np.argmax(f1))
            per_class.append(float(thr[min(bi, len(thr)-1)]) if len(thr)>0 else 0.5)
        except Exception:
            per_class.append(0.5)
    cand = np.linspace(0.2, 0.8, 25)
    best_t, best_f1 = 0.5, -1
    for t in cand:
        preds = (val_logits >= t).astype(int)
        fm = f1_score(val_labels, preds, average='macro', zero_division=0)
        if fm > best_f1:
            best_f1, best_t = fm, float(t)
    return {'global': best_t, 'per_class': per_class}

thr_en = tune_thresholds(val_probs, val_labels)
print('EN thresholds:', thr_en)
# Train on EN
from transformers import TrainingArguments, Trainer, set_seed
from sklearn.metrics import f1_score, roc_auc_score, precision_recall_curve
import numpy as np

set_seed(CFG.seed)

args_en = TrainingArguments(
    output_dir=CFG.out_dir,
    evaluation_strategy='epoch',
    save_strategy='epoch',
    learning_rate=CFG.lr,
    per_device_train_batch_size=CFG.train_bs,
    per_device_eval_batch_size=CFG.eval_bs,
    num_train_epochs=CFG.epochs_en,
    weight_decay=CFG.wd,
    warmup_ratio=CFG.warmup_ratio,
    fp16=CFG.fp16,
    load_best_model_at_end=True,
    metric_for_best_model='f1_macro',
    greater_is_better=True,
    report_to=['none'],
    save_total_limit=2,
)

sigmoid = torch.nn.Sigmoid()

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    probs = sigmoid(torch.tensor(logits)).numpy()
    preds = (probs >= 0.5).astype(int)
    out = {}
    try:
        out['roc_auc_macro'] = roc_auc_score(labels, probs, average='macro')
    except Exception:
        out['roc_auc_macro'] = float('nan')
    out['f1_micro'] = f1_score(labels, preds, average='micro', zero_division=0)
    out['f1_macro'] = f1_score(labels, preds, average='macro', zero_division=0)
    return out

trainer = Trainer(
    model=model,
    args=args_en,
    train_dataset=en_proc['train'],
    eval_dataset=en_proc['validation'],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)
trainer.train()
# Model & collator
import torch
from transformers import AutoModelForSequenceClassification, DataCollatorWithPadding

model = AutoModelForSequenceClassification.from_pretrained(
    CFG.model_name,
    num_labels=num_labels,
    problem_type='multi_label_classification'
)
model.gradient_checkpointing_enable()

data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8 if CFG.fp16 else None)
# Tokenizer & preprocess (shared)
from transformers import AutoTokenizer
import numpy as np

tokenizer = AutoTokenizer.from_pretrained(CFG.model_name, use_fast=True)

def preprocess(ds):
    def fn(examples):
        enc = tokenizer(examples['text'], max_length=CFG.max_length, truncation=True)
        mh = []
        for lbls in examples['labels']:
            arr = np.zeros(num_labels, dtype=np.float32)
            for i in lbls:
                arr[i] = 1.0
            mh.append(arr)
        enc['labels'] = mh
        return enc
    cols = ds['train'].column_names
    return ds.map(fn, batched=True, remove_columns=cols)

en_proc = preprocess(en_ds).with_format('torch')
# Load EN GoEmotions (raw, multilabel)
from datasets import load_dataset
import json

en_ds = load_dataset('go_emotions', 'raw')
label_names = en_ds['train'].features['labels'].feature.names
num_labels = len(label_names)
with open(os.path.join(CFG.out_dir, 'label_names.json'), 'w') as f:
    json.dump(label_names, f, ensure_ascii=False, indent=2)

print('EN splits:', en_ds)
print('Labels:', label_names)
# Config
from dataclasses import dataclass

@dataclass
class Config:
    model_name: str = 'xlm-roberta-base'
    out_dir: str = 'outputs/emotion_xlmr'
    max_length: int = 128
    train_bs: int = 32
    eval_bs: int = 32
    lr: float = 2e-5
    wd: float = 0.01
    warmup_ratio: float = 0.06
    epochs_en: int = 3
    epochs_ru: int = 2
    seed: int = 42
    fp16: bool = True

CFG = Config()
os.makedirs(CFG.out_dir, exist_ok=True)
print(CFG)
# Setup
import os, sys, subprocess

reqs = [
    'torch', 'transformers>=4.41.0', 'datasets>=2.19.0', 'evaluate>=0.4.2',
    'accelerate>=0.33.0', 'scikit-learn>=1.3.0', 'onnx>=1.15.0', 'onnxruntime>=1.17.0'
]

def pip_install(pkgs):
    subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q'] + pkgs)

try:
    import transformers, datasets, evaluate, sklearn, onnxruntime
except Exception:
    pip_install(reqs)
    import transformers, datasets, evaluate, sklearn, onnxruntime

print('Transformers:', transformers.__version__)
print('Datasets:', datasets.__version__)
### Текстовая классификация эмоций (EN → RU дообучение)

Полный Colab-ноутбук: установка, обучение на GoEmotions (EN), дообучение на русской версии GoEmotions, метрики, тюнинг порогов, экспорт PyTorch + ONNX, инференс.